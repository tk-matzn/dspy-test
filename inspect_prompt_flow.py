#!/usr/bin/env python3
"""
DSPyå†…éƒ¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæµã‚Œã‚’ç¢ºèªã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã€å…¥åŠ›ã€å‡ºåŠ›ã®è©³ç´°ãªãƒ­ã‚°ã‚’è¡¨ç¤ºã—ã¾ã™
"""

import os
import dspy
from dotenv import load_dotenv

# ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€
load_dotenv()

# ========== 1. DSPyã®è¨­å®š ==========
print("=" * 70)
print("1. DSPyè¨­å®š")
print("=" * 70)

# Azure OpenAIè¨­å®š
azure_key = os.getenv("AZURE_OPENAI_API_KEY")
azure_endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
api_version = os.getenv("AZURE_OPENAI_API_VERSION", "2024-02-15-preview")
deployment_name = os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME", "gpt-35-turbo")

if azure_key and azure_endpoint:
    dspy.configure(lm=dspy.LM(
        model=f"azure/{deployment_name}",
        api_key=azure_key,
        api_base=azure_endpoint,
        api_version=api_version,
        max_tokens=500
    ))
    print("âœ“ Azure OpenAI ãŒè¨­å®šã•ã‚Œã¾ã—ãŸ")
else:
    print("âœ— Azure OpenAI ã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
    exit(1)

# ========== 2. ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ãƒ­ã‚®ãƒ³ã‚°ã‚’æœ‰åŠ¹ã«ã™ã‚‹ ==========
print("\n" + "=" * 70)
print("2. DSPyãƒ­ã‚®ãƒ³ã‚°ã®æœ‰åŠ¹åŒ–")
print("=" * 70)

# DSPyã®å†…éƒ¨ãƒ­ã‚®ãƒ³ã‚°ã‚’ç¢ºèª
try:
    dspy.enable_logging()
    print("âœ“ DSPyãƒ­ã‚®ãƒ³ã‚°ã‚’æœ‰åŠ¹åŒ–ã—ã¾ã—ãŸ")
except Exception as e:
    print(f"ãƒ­ã‚®ãƒ³ã‚°æœ‰åŠ¹åŒ–: {e}")

# ========== 3. ã‚·ãƒ³ãƒ—ãƒ«ãªPredictã‚’å®Ÿè¡Œ ==========
print("\n" + "=" * 70)
print("3. ã‚·ãƒ³ãƒ—ãƒ«ãªPredictå®Ÿè¡Œ")
print("=" * 70)

# Predictã®å®šç¾©
simple_predict = dspy.Predict("question -> answer")

question = "Pythonã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ"
print(f"\nğŸ“ å…¥åŠ›è³ªå•: {question}")
print("-" * 70)

# å®Ÿè¡Œ
result = simple_predict(question=question)

print(f"\nâœ… å‡ºåŠ›å›ç­”: {result.answer}")

# ========== 4. å®Ÿè¡Œå±¥æ­´ã‚’ç¢ºèª ==========
print("\n" + "=" * 70)
print("4. DSPyå®Ÿè¡Œå±¥æ­´ã®ç¢ºèª")
print("=" * 70)

# è¨­å®šã‹ã‚‰LMã‚’å–å¾—ã—ã¦å±¥æ­´ã‚’ç¢ºèª
lm = dspy.settings.lm

print(f"\nä½¿ç”¨ã—ãŸLMãƒ¢ãƒ‡ãƒ«: {lm.model}")
print(f"API Base: {lm.api_base if hasattr(lm, 'api_base') else 'N/A'}")
print(f"Max Tokens: {lm.max_tokens}")

# ========== 5. è¤‡é›‘ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ãƒ­ãƒ¼ ==========
print("\n" + "=" * 70)
print("5. è¤‡é›‘ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ãƒ­ãƒ¼ï¼ˆè¤‡æ•°ã‚¹ãƒ†ãƒƒãƒ—ï¼‰")
print("=" * 70)

class MultiStepPipeline(dspy.Module):
    """è¤‡æ•°ã‚¹ãƒ†ãƒƒãƒ—ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³"""
    def __init__(self):
        super().__init__()
        # Step 1: ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæŠ½å‡º
        self.extract_key_points = dspy.Predict("text -> key_points")
        # Step 2: è¦ç´„ä½œæˆ
        self.create_summary = dspy.Predict("key_points -> summary")
    
    def forward(self, text):
        print("\n[Step 1] ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæŠ½å‡º")
        print(f"å…¥åŠ›: {text[:50]}...")
        
        # Step 1å®Ÿè¡Œ
        result_step1 = self.extract_key_points(text=text)
        print(f"å‡ºåŠ›: {result_step1.key_points[:80]}...")
        
        print("\n[Step 2] è¦ç´„ä½œæˆ")
        print(f"å…¥åŠ›: {result_step1.key_points[:50]}...")
        
        # Step 2å®Ÿè¡Œ
        result_step2 = self.create_summary(key_points=result_step1.key_points)
        print(f"å‡ºåŠ›: {result_step2.summary}")
        
        return dspy.Prediction(
            original_text=text,
            key_points=result_step1.key_points,
            summary=result_step2.summary
        )

# ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè¡Œ
pipeline = MultiStepPipeline()

text = "DSPyã¯è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã™ã‚‹ãŸã‚ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã™ã€‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå·¥å­¦ã‚’è‡ªå‹•åŒ–ã—ã€ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åŒ–ã•ã‚ŒãŸAIã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚"
print(f"\nğŸ“ å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ: {text}\n")
print("-" * 70)

result = pipeline(text=text)

# ========== 6. ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®ç¢ºèª ==========
print("\n" + "=" * 70)
print("6. ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®è©³ç´°")
print("=" * 70)

# Predictã®ã‚·ã‚°ãƒãƒãƒ£ã‚’ç¢ºèª
predict_sig = simple_predict.signature
print(f"\nã‚·ã‚°ãƒãƒãƒ£: {predict_sig}")
print(f"å…¥åŠ›ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰: {list(predict_sig.input_fields.keys())}")
print(f"å‡ºåŠ›ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰: {list(predict_sig.output_fields.keys())}")

# ========== 7. APIå‘¼ã³å‡ºã—ã®è©³ç´°ãƒ­ã‚° ==========
print("\n" + "=" * 70)
print("7. LMè¨­å®šã®è©³ç´°")
print("=" * 70)

lm = dspy.settings.lm
print(f"\nLMã‚¯ãƒ©ã‚¹: {lm.__class__.__name__}")
print(f"ãƒ¢ãƒ‡ãƒ«: {lm.model}")
print(f"Max Tokens: {lm.max_tokens}")

if hasattr(lm, 'api_base'):
    print(f"API Base: {lm.api_base}")
if hasattr(lm, 'api_version'):
    print(f"API Version: {lm.api_version}")

# ========== 8. ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå®Ÿè¡Œã®æµã‚Œã‚’å›³ç¤º ==========
print("\n" + "=" * 70)
print("8. ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå®Ÿè¡Œãƒ•ãƒ­ãƒ¼")
print("=" * 70)

flow = """
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          DSPy ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå®Ÿè¡Œãƒ•ãƒ­ãƒ¼                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚³ãƒ¼ãƒ‰
   â†“
   question = "Pythonã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ"
   result = predict(question=question)
   
2. Predict/ChainOfThoughtãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
   â†“
   â€¢ ã‚·ã‚°ãƒãƒãƒ£ã‚’è§£æ
   â€¢ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½œæˆ
   â€¢ å…¥åŠ›ã‚’å½¢å¼åŒ–
   
3. ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
   â†“
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ               â”‚
   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
   â”‚ You are an expert AI assistant   â”‚
   â”‚ that follows instructions...     â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ ã‚¿ã‚¹ã‚¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ                 â”‚
   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
   â”‚ Question -> Answer                â”‚
   â”‚ ---                              â”‚
   â”‚ Question: Pythonã¨ã¯...          â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

4. LM APIå‘¼ã³å‡ºã—
   â†“
   LM.forward(prompt)
   â†“
   â€¢ Azure OpenAI APIã«é€ä¿¡
   â€¢ APIãƒ¬ã‚¹ãƒãƒ³ã‚¹å—ä¿¡
   
5. å¿œç­”è§£æ
   â†“
   â€¢ LLMã®å‡ºåŠ›ã‚’è§£æ
   â€¢ ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æŠ½å‡º
   
6. çµæœè¿”å´
   â†“
   Prediction(answer="Pythonã¯...ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã§ã™")
"""

print(flow)

# ========== 9. ãƒ‡ãƒãƒƒã‚°æƒ…å ± ==========
print("\n" + "=" * 70)
print("9. ãƒ‡ãƒãƒƒã‚°æƒ…å ±")
print("=" * 70)

# ç¾åœ¨ã®è¨­å®šã‚’è¡¨ç¤º
settings = dspy.settings
print(f"\nç¾åœ¨ã®DSPyè¨­å®š:")
print(f"  LM: {settings.lm}")
print(f"  RM (Retriever): {settings.rm if hasattr(settings, 'rm') else 'N/A'}")

# ========== 10. ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœ€é©åŒ–ã®å¯èƒ½æ€§ ==========
print("\n" + "=" * 70)
print("10. ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœ€é©åŒ–ã®æ©Ÿèƒ½")
print("=" * 70)

optimization_info = """
DSPyã§åˆ©ç”¨å¯èƒ½ãªæœ€é©åŒ–æ©Ÿèƒ½:

1. BootstrapFewShot
   - è‡ªå‹•çš„ã«è‰¯ã„ä¾‹ï¼ˆfew-shotï¼‰ã‚’ç”Ÿæˆ
   - ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®åŠ¹æœã‚’å‘ä¸Šã•ã›ã‚‹

2. COPRO (Chain-of-Thought Optimization)
   - æ€è€ƒéç¨‹ã‚’è‡ªå‹•æœ€é©åŒ–
   - ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®æ”¹å–„

3. MIPROv2
   - è¤‡æ•°ãƒ¡ãƒˆãƒªãƒƒã‚¯ã®æœ€é©åŒ–
   - ã‚ˆã‚Šè¤‡é›‘ãªã‚¿ã‚¹ã‚¯å‘ã‘

4. GEPA (Gradual Evolution with Prompt Adaptation)
   - æ®µéšçš„ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé€²åŒ–
   - ç²¾åº¦å‘ä¸Šã‚’é‡è¦–

ä½¿ç”¨ä¾‹:
    from dspy.teleprompt import BootstrapFewShot
    
    optimizer = BootstrapFewShot(
        metric=accuracy_metric,
        max_bootstrapped_demos=4
    )
    optimized_program = optimizer.compile(program, trainset)
"""

print(optimization_info)

print("\n" + "=" * 70)
print("âœ… ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæµã‚Œã®ç¢ºèªãŒå®Œäº†ã—ã¾ã—ãŸ")
print("=" * 70)
